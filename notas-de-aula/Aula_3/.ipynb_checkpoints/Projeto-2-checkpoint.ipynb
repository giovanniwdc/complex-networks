{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "usual-bumper",
   "metadata": {},
   "source": [
    "# **Projeto 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polar-franklin",
   "metadata": {},
   "source": [
    "## **Questão 1)** Para a rede “Hamsterster”, calcule a média dos menores caminhos e o diâmetro.Use apenas o maior componente da rede e remova ciclos ou auto-conexões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "contrary-space",
   "metadata": {},
   "outputs": [],
   "source": [
    "hamsterster = clean_graph(nx.read_edgelist('./data/hamsterster.txt', nodetype = int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "unable-characteristic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Média dos menores caminhos para a rede Hamsterster: 3.45\n"
     ]
    }
   ],
   "source": [
    "hamsterster_avarage_shortest_path = nx.average_shortest_path_length(hamsterster)\n",
    "\n",
    "print(f'Média dos menores caminhos para a rede Hamsterster: {hamsterster_avarage_shortest_path:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "significant-nebraska",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diametro do maior componente da rede Hamsterster: 14\n"
     ]
    }
   ],
   "source": [
    "hamsterster_diameter = nx.diameter(hamsterster)\n",
    "\n",
    "print(f'Diametro do maior componente da rede Hamsterster: {hamsterster_diameter}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "residential-rugby",
   "metadata": {},
   "source": [
    "## **Questão 2)** Considere a rede “USairport500” e calcule a média e variância dos menores caminhos. Use apenas o maior componente da rede e remova ciclos ou autoconexões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "awful-rebate",
   "metadata": {},
   "outputs": [],
   "source": [
    "usairport = clean_graph(nx.read_edgelist('./data/usairport.txt', nodetype = int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "worst-bangkok",
   "metadata": {},
   "outputs": [],
   "source": [
    "usairport_shortest_paths = nx.shortest_path_length(usairport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "exotic-scroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "vsp = []\n",
    "\n",
    "for i in usairport_shortest_paths:\n",
    "    \n",
    "    vs = np.array(list(dict(i[1]).values()))[1:]\n",
    "    \n",
    "    for j in vs:\n",
    "        \n",
    "        vsp.append(j)\n",
    "        \n",
    "vsp = np.array(vsp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "mediterranean-drawing",
   "metadata": {},
   "outputs": [],
   "source": [
    "usairport_N = len(usairport.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "considered-vision",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Média: 3 e variância: 1 da rede Usairport\n"
     ]
    }
   ],
   "source": [
    "usairport_mean = vsp.sum()/(usairport_N*(usairport_N - 1))\n",
    "usairport_var = sum((vsp - usairport_mean)**2)/(usairport_N*(usairport_N - 1))\n",
    "\n",
    "print(f'Média: {usairport_mean:.0f} e variância: {usairport_var:.0f} da rede Usairport')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defensive-motor",
   "metadata": {},
   "source": [
    "## **Questão 3)** Para a rede “USairport500”, calcule a entropia de Shannon da distribuição dos menores caminhos. Use logaritmo na base 2 e considere apenas o maior componente da rede."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "unsigned-holocaust",
   "metadata": {},
   "outputs": [],
   "source": [
    "se = shortest_path_length_shannon_entropy(usairport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "measured-packet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shannon entropy: 1.88\n"
     ]
    }
   ],
   "source": [
    "print(f'Shannon entropy: {se:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "remarkable-providence",
   "metadata": {},
   "source": [
    "## **Questão 4)** Calcule o coeficiente de assortatividade da rede Advogato. Considere apenas o maior componente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "intermediate-distance",
   "metadata": {},
   "outputs": [],
   "source": [
    "advogato = clean_graph(nx.read_edgelist('./data/advogato.txt', nodetype = int), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "intellectual-clothing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Global Efficiency: -0.08455192594199333\n"
     ]
    }
   ],
   "source": [
    "advogato_efficiency = nx.degree_assortativity_coefficient(advogato)\n",
    "\n",
    "print(f'Network Global Efficiency: {advogato_efficiency}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specific-division",
   "metadata": {},
   "source": [
    "## **Questão 5)** Calcule o coeficiente de correlação de Pearson entre o grau médio dos vizinhos e o grau de cada vértice para a rede “word_adjacencies”. Isto é, entre k e knn(k). Use apenas o maior componente. Considere o exemplo da aula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fatal-hudson",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_adjacencies = clean_graph(nx.read_edgelist('./data/word_adjacencies.txt', nodetype = int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ambient-recording",
   "metadata": {},
   "outputs": [],
   "source": [
    "ki = []\n",
    "kj = []\n",
    "\n",
    "N = len(word_adjacencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "sexual-photograph",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(N):\n",
    "    for j in np.arange(N):\n",
    "        \n",
    "        if word_adjacencies.has_edge(i, j) == True:\n",
    "            \n",
    "            ki.append(word_adjacencies.degree(i))\n",
    "            kj.append(word_adjacencies.degree(j)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "color-digest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation: -0.12934785343900151\n"
     ]
    }
   ],
   "source": [
    "corr, _ = pearsonr(ki, kj)\n",
    "\n",
    "print(f'Pearson correlation: {corr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominant-order",
   "metadata": {},
   "source": [
    "## **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "quiet-given",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sorted-impression",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "empty-venice",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "native-delay",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr, spearmanr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quick-budapest",
   "metadata": {},
   "source": [
    "## **Settings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "strange-breast",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "innocent-charger",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('axes', titlesize=18)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=14)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=13)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=13)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=13)    # legend fontsize\n",
    "plt.rc('font', size=13)          # controls default text sizes\n",
    "plt.rc('figure', figsize = (8,8)) # Set the figure size "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retired-tattoo",
   "metadata": {},
   "source": [
    "## **Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "western-amber",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortest_path_length_shannon_entropy(G):\n",
    "    \n",
    "    _, Ppath = shortest_path_distribution(G)\n",
    "    \n",
    "    H = 0 \n",
    "    \n",
    "    for p in Ppath:\n",
    "        \n",
    "        if p > 0 :\n",
    "            H -= p*np.log2(p)\n",
    "    \n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "hungry-african",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortest_path_distribution(G):\n",
    "    \n",
    "    shortest_paths = nx.shortest_path_length(G)\n",
    "    \n",
    "    shortest_paths_values = []\n",
    "    \n",
    "    for paths in shortest_paths:\n",
    "    \n",
    "        values = np.array(list(dict(paths[1]).values()))[1:]\n",
    "    \n",
    "        for value in values:\n",
    "        \n",
    "            shortest_paths_values.append(value)\n",
    "    \n",
    "    shortest_paths_values = np.array(shortest_paths_values)\n",
    "    \n",
    "    maxk = shortest_paths_values.max()\n",
    "    mink = shortest_paths_values.min()\n",
    "    \n",
    "    paths_values = np.arange(maxk + 1)\n",
    "    \n",
    "    Ppath = np.zeros(maxk + 1)\n",
    "    \n",
    "    for path in shortest_paths_values:\n",
    "        \n",
    "        Ppath[path] += 1\n",
    "        \n",
    "    Ppath = Ppath/Ppath.sum()\n",
    "    \n",
    "    return paths_values, Ppath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "virtual-causing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_graph(G, remove_edges = True):\n",
    "    \n",
    "    G = G.to_undirected()\n",
    "    \n",
    "    if remove_edges:\n",
    "        \n",
    "        G.remove_edges_from(nx.selfloop_edges(G))\n",
    "    \n",
    "    G_cc = sorted(nx.connected_components(G), key = len, reverse =True)\n",
    "    G = G.subgraph(G_cc[0])\n",
    "    G = nx.convert_node_labels_to_integers(G, first_label = 0 )\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "detected-broadcasting",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(G):\n",
    "    \n",
    "    knn_G = np.zeros(len(G.nodes), dtype = float)\n",
    "    \n",
    "    for i in G.nodes:\n",
    "\n",
    "        aux = nx.average_neighbor_degree(G, nodes = [i])\n",
    "        knn_G[i] = float(aux[i])\n",
    "\n",
    "    return knn_G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "noticed-weight",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knnk(G):\n",
    "    \n",
    "    knnk_G = []\n",
    "    ks_G = []\n",
    "    \n",
    "    knn_G = knn(G)\n",
    "    \n",
    "    vk = np.array(list(dict(G.degree).values()))\n",
    "    \n",
    "    for k in np.arange(vk.min(), vk.max() + 1):\n",
    "    \n",
    "        aux = vk == k\n",
    "\n",
    "        if len(knn_G[aux]) > 0 :\n",
    "\n",
    "            average_knn = knn_G[aux].mean()\n",
    "\n",
    "            knnk_G.append(average_knn)\n",
    "\n",
    "            ks_G.append(k)\n",
    "            \n",
    "    return ks_G, knnk_G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experienced-holiday",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "necessary-hearing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pending-employee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
