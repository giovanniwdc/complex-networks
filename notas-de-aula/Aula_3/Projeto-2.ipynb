{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "breathing-dinner",
   "metadata": {},
   "source": [
    "# **Projeto 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entitled-powell",
   "metadata": {},
   "source": [
    "## **Questão 1)** Para a rede “Hamsterster”, calcule a média dos menores caminhos e o diâmetro.Use apenas o maior componente da rede e remova ciclos ou auto-conexões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "entitled-token",
   "metadata": {},
   "outputs": [],
   "source": [
    "hamsterster = clean_graph(nx.read_edgelist('./data/hamsterster.txt', nodetype = int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "spiritual-draft",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Média dos menores caminhos para a rede Hamsterster: 3.45\n"
     ]
    }
   ],
   "source": [
    "hamsterster_avarage_shortest_path = nx.average_shortest_path_length(hamsterster)\n",
    "\n",
    "print(f'Média dos menores caminhos para a rede Hamsterster: {hamsterster_avarage_shortest_path:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "executed-circle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diametro do maior componente da rede Hamsterster: 14\n"
     ]
    }
   ],
   "source": [
    "hamsterster_diameter = nx.diameter(hamsterster)\n",
    "\n",
    "print(f'Diametro do maior componente da rede Hamsterster: {hamsterster_diameter}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "presidential-termination",
   "metadata": {},
   "source": [
    "## **Questão 2)** Considere a rede “USairport500” e calcule a média e variância dos menores caminhos. Use apenas o maior componente da rede e remova ciclos ou autoconexões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "corrected-shell",
   "metadata": {},
   "outputs": [],
   "source": [
    "usairport = clean_graph(nx.read_edgelist('./data/usairport.txt', nodetype = int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "sapphire-consent",
   "metadata": {},
   "outputs": [],
   "source": [
    "usairport_1_moment_shortest_path = momment_of_shortest_path_length_distribution(usairport, 1)\n",
    "usairport_2_moment_shortest_path = momment_of_shortest_path_length_distribution(usairport, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "tropical-brother",
   "metadata": {},
   "outputs": [],
   "source": [
    "usairport_shortest_path_var = usairport_2_moment_shortest_path - usairport_1_moment_shortest_path**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "novel-slave",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Média: 3 e variância: 1 da rede Usairport\n"
     ]
    }
   ],
   "source": [
    "print(f'Média: {first_moment_shortest_path:.0f} e variância: {usairport_shortest_path_var:.0f} da rede Usairport')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compliant-daughter",
   "metadata": {},
   "source": [
    "## **Questão 3)** Para a rede “USairport500”, calcule a entropia de Shannon da distribuição dos menores caminhos. Use logaritmo na base 2 e considere apenas o maior componente da rede."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "former-stanford",
   "metadata": {},
   "outputs": [],
   "source": [
    "usairport_shortest_path_shannon_entropy = shortest_path_length_shannon_entropy(usairport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cleared-citizenship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shannon entropy: 1.88\n"
     ]
    }
   ],
   "source": [
    "print(f'Shannon entropy: {usairport_shortest_path_shannon_entropy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expressed-characteristic",
   "metadata": {},
   "source": [
    "## **Questão 4)** Calcule o coeficiente de assortatividade da rede Advogato. Considere apenas o maior componente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "republican-indian",
   "metadata": {},
   "outputs": [],
   "source": [
    "advogato = clean_graph(nx.read_edgelist('./data/advogato.txt', nodetype = int), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "consecutive-joyce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Global Efficiency: -0.08455192594199333\n"
     ]
    }
   ],
   "source": [
    "advogato_efficiency = nx.degree_assortativity_coefficient(advogato)\n",
    "\n",
    "print(f'Network Global Efficiency: {advogato_efficiency}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signed-complexity",
   "metadata": {},
   "source": [
    "## **Questão 5)** Calcule o coeficiente de correlação de Pearson entre o grau médio dos vizinhos e o grau de cada vértice para a rede “word_adjacencies”. Isto é, entre k e knn(k). Use apenas o maior componente. Considere o exemplo da aula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "protecting-merit",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_adjacencies = clean_graph(nx.read_edgelist('./data/word_adjacencies.txt', nodetype = int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "numerical-adams",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_adjacencies_k, word_adjacencies_Pk = knnk(word_adjacencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "jewish-priest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation: -0.6753041480047248\n"
     ]
    }
   ],
   "source": [
    "pearson_ksknnk = np.corrcoef(word_adjacencies_k, word_adjacencies_Pk)[0, 1]\n",
    "\n",
    "print(f'Pearson correlation: {pearson_ksknnk}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "injured-rugby",
   "metadata": {},
   "source": [
    "## **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "gothic-ticket",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "written-vertical",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "collaborative-array",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "educational-modification",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr, spearmanr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "induced-colors",
   "metadata": {},
   "source": [
    "## **Settings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "norman-electricity",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "accessible-decade",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('axes', titlesize=18)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=14)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=13)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=13)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=13)    # legend fontsize\n",
    "plt.rc('font', size=13)          # controls default text sizes\n",
    "plt.rc('figure', figsize = (8,8)) # Set the figure size "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invalid-duration",
   "metadata": {},
   "source": [
    "## **Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "chicken-wrapping",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortest_path_length_shannon_entropy(G):\n",
    "    \n",
    "    _, Ppath = shortest_path_distribution(G)\n",
    "    \n",
    "    H = 0 \n",
    "    \n",
    "    for p in Ppath:\n",
    "        \n",
    "        if p > 0 :\n",
    "            H -= p*np.log2(p)\n",
    "    \n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "french-struggle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def momment_of_shortest_path_length_distribution(G, m):\n",
    "    \n",
    "    V, P = shortest_path_distribution(G)\n",
    "    \n",
    "    M = np.sum((V**m)*P)\n",
    "    \n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "great-description",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortest_path_distribution(G):\n",
    "    \n",
    "    shortest_paths = nx.shortest_path_length(G)\n",
    "    \n",
    "    shortest_paths_values = []\n",
    "    \n",
    "    for paths in shortest_paths:\n",
    "    \n",
    "        values = np.array(list(dict(paths[1]).values()))[1:]\n",
    "    \n",
    "        for value in values:\n",
    "        \n",
    "            shortest_paths_values.append(value)\n",
    "    \n",
    "    shortest_paths_values = np.array(shortest_paths_values)\n",
    "    \n",
    "    maxk = shortest_paths_values.max()\n",
    "    mink = shortest_paths_values.min()\n",
    "    \n",
    "    paths_values = np.arange(maxk + 1)\n",
    "    \n",
    "    Ppath = np.zeros(maxk + 1)\n",
    "    \n",
    "    for path in shortest_paths_values:\n",
    "        \n",
    "        Ppath[path] += 1\n",
    "        \n",
    "    Ppath = Ppath/Ppath.sum()\n",
    "    \n",
    "    return paths_values, Ppath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "quarterly-uniform",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knnk(G):\n",
    "    \n",
    "    knnk_G = []\n",
    "    ks_G = []\n",
    "    \n",
    "    knn_G = knn(G)\n",
    "    \n",
    "    vk = np.array(list(dict(G.degree).values()))\n",
    "    \n",
    "    for k in np.arange(vk.min(), vk.max()):\n",
    "    \n",
    "        aux = vk == k\n",
    "\n",
    "        if len(knn_G[aux]) > 0 :\n",
    "\n",
    "            average_knn = knn_G[aux].mean()\n",
    "\n",
    "            knnk_G.append(average_knn)\n",
    "\n",
    "            ks_G.append(k)\n",
    "            \n",
    "    return ks_G, knnk_G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "sensitive-olive",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(G):\n",
    "    \n",
    "    knn_G = np.zeros(len(G.nodes), dtype = float)\n",
    "    \n",
    "    for i in G.nodes:\n",
    "\n",
    "        aux = nx.average_neighbor_degree(G, nodes = [i])\n",
    "        knn_G[i] = float(aux[i])\n",
    "\n",
    "    return knn_G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "hairy-speed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_graph(G, remove_edges = True):\n",
    "    \n",
    "    G = G.to_undirected()\n",
    "    \n",
    "    if remove_edges:\n",
    "        \n",
    "        G.remove_edges_from(nx.selfloop_edges(G))\n",
    "    \n",
    "    G_cc = sorted(nx.connected_components(G), key = len, reverse =True)\n",
    "    G = G.subgraph(G_cc[0])\n",
    "    G = nx.convert_node_labels_to_integers(G, first_label = 0 )\n",
    "    \n",
    "    return G"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
